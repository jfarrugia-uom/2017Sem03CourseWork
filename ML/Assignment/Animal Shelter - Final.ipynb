{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution = 0.02):\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    \n",
    "    #plot surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    \n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.9, c=cmap(idx), marker=markers[idx], label = cl)\n",
    "        \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid, expl_variables, _ = get_train_valid_sets(model_frames[2], animal='both', include_svd=False)\n",
    "print expl_variables\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_valid_std = sc.transform(X_valid)\n",
    "lr = LogisticRegression(random_state=22, multi_class='multinomial', solver='lbfgs')\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_valid_pca = pca.transform(X_valid_std)\n",
    "lr.fit(X_train_pca, y_train)\n",
    "plot_decision_regions(X_valid_pca[:200,:], y_valid[:200], classifier=lr)\n",
    "plt.xlabel('PC1')\n",
    "plt.xlabel('PC2')\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "lr.score(X_valid_pca, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot roc-auc \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# get set most suited for RF\n",
    "X_train, X_valid, y_train, y_valid, expl_variables, classes = get_train_valid_sets(model_frames[3], 'both')\n",
    "\n",
    "y_valid_bin = label_binarize(y_valid, classes=[0,1,2,3,4])\n",
    "gs_rf = gs_rf.fit(X_train, y_train)\n",
    "roc_predictions = gs_rf.predict(X_valid)\n",
    "roc_prob = gs_rf.predict_proba(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform nested cross validation to find out generalised error used hyperparameter tuned Log Reg\n",
    "pipe_lr = Pipeline([('min_max', MinMaxScaler()),\n",
    "                    ('clf', LogisticRegression(random_state=22))])\n",
    "\n",
    "param_range = [1.0, 10.0, 100.0]\n",
    "param_grid = [{'clf__multi_class':['ovr'],\n",
    "               'clf__solver':['liblinear'],\n",
    "               'clf__class_weight':[None,'balanced'],\n",
    "               'clf__C':param_range},\n",
    "              {'clf__multi_class':['multinomial'],\n",
    "               'clf__solver':['sag'],\n",
    "               'clf__C':param_range}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_lr, param_grid=param_grid, scoring='neg_log_loss', cv=2)\n",
    "# get set most suited for LR\n",
    "model_df = get_features(df, mode=3)\n",
    "X_train, X_valid, y_train, y_valid, expl_variables, _ = get_train_valid_sets(model_frames[2], 'both')\n",
    "print expl_variables\n",
    "\n",
    "scores = cross_val_score(gs, X_train, y_train, scoring='neg_log_loss', verbose=True)\n",
    "print \"Cross val Logistic Regression log loss: %.3f +/- %.3f\" % (np.mean(scores), np.std(scores))\n",
    "\n",
    "# Cross val log loss: -0.812 +/- 0.010\n",
    "\n",
    "# Cross val Logistic Regression log loss: -0.888 +/- 0.012 # with et's age categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = gs.fit(X_train, y_train)\n",
    "valid_prediction = gs.predict(X_valid)\n",
    "valid_prediction_prob = gs.predict_proba(X_valid)\n",
    "print(classification_report(y_valid, valid_prediction, target_names=classes))\n",
    "print log_loss(y_valid, valid_prediction_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
