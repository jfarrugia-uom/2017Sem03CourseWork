{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec # pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load trained model\n",
    "model = word2vec.Word2Vec.load(\"200features_30minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'gross', 0.7470200061798096),\n",
       " (u'awful', 0.7391952276229858),\n",
       " (u'edible', 0.6546488404273987),\n",
       " (u'tasteless', 0.6506273746490479),\n",
       " (u'meh', 0.6375978589057922),\n",
       " (u'horrible', 0.6174852252006531),\n",
       " (u'bland', 0.6133885383605957),\n",
       " (u'alright', 0.6046308279037476),\n",
       " (u'terrible', 0.6013745665550232),\n",
       " (u'inedible', 0.596312403678894)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find synonyms\n",
    "model.wv.most_similar(\"disgusting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'seafood', 0.5753906965255737),\n",
       " (u'noodles', 0.5618176460266113),\n",
       " (u'udon', 0.5462554693222046),\n",
       " (u'broccoli', 0.5354248285293579),\n",
       " (u'vegetable', 0.5339387059211731),\n",
       " (u'rice', 0.5258793830871582),\n",
       " (u'bibimbap', 0.5200287103652954),\n",
       " (u'noodle', 0.5142123103141785),\n",
       " (u'mein', 0.509763240814209),\n",
       " (u'soba', 0.5056496858596802)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of word algebra similar to the classic king + woman - man => queen\n",
    "# pasta + chinese - italian => [noodle, udon, etc.]\n",
    "model.wv.most_similar(positive=['pasta','chinese'], negative=['italian'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test one review\n",
    "print process_review(pd_review[\"text\"][0])\n",
    "clean_reviews = pd_review[\"text\"].apply(lambda x: process_review(x,True,True,True))\n",
    "\n",
    "# now create bag-of-words with vectoriser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# limit vocab to 5000 words for now\n",
    "cv = CountVectorizer(analyzer='word', tokenizer=None, preprocessor=None,\n",
    "                     stop_words = None, max_features=5000)\n",
    "\n",
    "review_features = cv.fit_transform(clean_reviews)\n",
    "# convert from sparse matrix to numpy array\n",
    "review_features = review_features.toarray()\n",
    "\n",
    "# check size of bag of words model\n",
    "print review_features.shape\n",
    "# have a look at the vocab\n",
    "#print cv.get_feature_names()\n",
    "\n",
    "def get_top_n_features(bow, cv, n):\n",
    "    weights = bow.mean(axis=0).ravel().tolist()\n",
    "    weights_df = pd.DataFrame({'term': cv.get_feature_names(), 'weight':weights})\n",
    "    print weights_df.sort_values(by='weight', ascending=False).head(n)    \n",
    "\n",
    "# print 50 top terms\n",
    "get_top_n_features(review_features, cv, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
