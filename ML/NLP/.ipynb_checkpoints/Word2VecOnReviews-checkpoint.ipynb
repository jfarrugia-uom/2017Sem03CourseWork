{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec example with gensim, NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb as mysql\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "import re # regular expression library\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download text datasets including stop words\n",
    "#nltk.download() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hook up to mysql\n",
    "# to fix ascii problem when tokenising, important to specify character set\n",
    "# https://stackoverflow.com/questions/21129020/how-to-fix-unicodedecodeerror-ascii-codec-cant-decode-byte\n",
    "db = mysql.connect(\"localhost\", \"jfarrugia\", \"jfarrugia\", \"yelp_db\", charset='utf8',\n",
    "use_unicode=True)\n",
    "# load some data\n",
    "pd_review = pd.read_sql(\"select id, name, text, stars from toronto_50K_random_reviews\", con=db)\n",
    "# close connection\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 4)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm review shape\n",
    "pd_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Not too bad overall. Got the 4 course menu which included a whole fish (grilled or seared) an appetizer and desert. The fish was wonderful. The pita appetizer was ok but one of the dips was not very good. I can't comment on dessert as I didn't try it. The others at my table seemed to think it was ok. The service was pretty good. Nothing special. We did think it was odd that the waiter spoke to people at the front door while he was taking our order. Not too bad overall. Would go back but won't be sprinting.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show 1 review\n",
    "pd_review[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details from https://www.kaggle.com/c/word2vec-nlp-tutorial#part-1-for-beginners-bag-of-words\n",
    "# lower case all text\n",
    "lc_review = pd_review[\"text\"][0].lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split one review into separate words\n",
    "words = lc_review.split(\" \")\n",
    "# remove stop words from review text\n",
    "words_no_stop = [w for w in words if w not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'came', u'thursday', u'night', u'take', u'advantag', u'groupon', u'husbi', u'purchased.', u'20', u'min', u'wait', u'till', u'got', u'seated.', u'needless', u'say', u'busi', u'restaur', u'-', u'busiest', u'street', u'infact.\\nth', u'server', u'friendli', u'welcoming.', u'felt', u'went', u'way', u'make', u'us', u'comfortable,', u'alway', u'nice!', u'order', u'zil', u'zil', u'tib', u'lalibela', u'special', u'one.', u'huge', u'portions,', u'could', u'finish', u'all.', u'yummi', u'serv', u'bit', u'salti', u'tasting,', u'overal', u'good.', u'however,', u'best', u'ethiopian', u'food', u'had,', u'compare.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "# removel morphological affices from words, leaving word stem\n",
    "stemmer = PorterStemmer()\n",
    "words_no_stop_stem = [stemmer.stem(w) for w in words_no_stop]\n",
    "print words_no_stop_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(base_review, remove_stop=False, stem = False, join=False):\n",
    "    words = re.sub(\"[^a-zA-Z0-9]\", \" \", base_review) \n",
    "    # convert to lower case + split    \n",
    "    words = words.lower().split(\" \")    \n",
    "    # searching a set is faster than a list    \n",
    "    # might contemplate tweaking stop word list\n",
    "    #stop = {x for x in set(stopwords.words(\"english\")) if x not in ['not', 'no']\n",
    "    if remove_stop:\n",
    "        stop = set(stopwords.words(\"english\"))\n",
    "        words = [word for word in words if word not in stop]\n",
    "    # run porter stemmer\n",
    "    if stem:\n",
    "        words = [stemmer.stem(w) for w in words]\n",
    "    # return string\n",
    "    if join:\n",
    "        return \" \".join(words)\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "came here on a thursday night to take advantag or a groupon the husbi purchas  it wa a 20 min wait till we got seat  needless to say it is a veri busi restaur   the busiest on the street infact  the server were friendli and welcom  i felt they went out of their way to make us comfort  which is alway nice  we order the zil zil tib and the lalibela special for one  huge portion  we could not finish it all  some of the yummi serv were a bit salti for my tast  but overal it wa good  thi is howev  not the best ethiopian food i have had  if i had to compar \n"
     ]
    }
   ],
   "source": [
    "# test one review\n",
    "print process_review(pd_review[\"text\"][0])\n",
    "clean_reviews = pd_review[\"text\"].apply(process_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create bag-of-words with vectoriser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# limit vocab to 5000 words for now\n",
    "cv = CountVectorizer(analyzer='word', tokenizer=None, preprocessor=None,\n",
    "                     stop_words = None, max_features=5000)\n",
    "\n",
    "review_features = cv.fit_transform(clean_reviews)\n",
    "# convert from sparse matrix to numpy array\n",
    "review_features = review_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5000)\n",
      "        term  weight\n",
      "1745    food  0.8358\n",
      "3312   place  0.7465\n",
      "1915    good  0.6963\n",
      "3083   order  0.5654\n",
      "2570    like  0.5131\n",
      "1954   great  0.4472\n",
      "3871  servic  0.4404\n",
      "4518    time  0.4299\n",
      "3067     one  0.3987\n",
      "1903      go  0.3918\n"
     ]
    }
   ],
   "source": [
    "# check size of bag of words model\n",
    "print review_features.shape\n",
    "# have a look at the vocab\n",
    "#print cv.get_feature_names()\n",
    "\n",
    "def get_top_n_features(bow, cv, n):\n",
    "    weights = bow.mean(axis=0).ravel().tolist()\n",
    "    weights_df = pd.DataFrame({'term': cv.get_feature_names(), 'weight':weights})\n",
    "    print weights_df.sort_values(by='weight', ascending=False).head(n)    \n",
    "\n",
    "# print 50 top terms\n",
    "get_top_n_features(review_features, cv, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec requires review paragraphs split into individual sentences\n",
    "# the datastructure to hold this data is a list of lists - \n",
    "# inner list holds sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NLTK's punkt includes a pre-trained tokenizer for english which can\n",
    "# be used to transform (split) new paragraph observations into sentences\n",
    "punkt = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split review corpus into sentences\n",
    "# cannot use clean_reviews since punctuation was removed\n",
    "\n",
    "#process_review(pd_review[\"text\"][0], False, False, False)\n",
    "def split_to_sentence(base_reviews, tokeniser, remove_stop=False):\n",
    "    raw_sentences = tokeniser.tokenize(base_reviews.strip())\n",
    "    sentences = []\n",
    "    for rs in raw_sentences:\n",
    "        # consider only strings with length >= 1\n",
    "        if (len(rs) > 0):\n",
    "            sentences.append( process_review(rs, remove_stop=remove_stop) )\n",
    "    return sentences\n",
    "\n",
    "sentences = pd_review[\"text\"].apply(lambda x: split_to_sentence(x, punkt)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'my', u'pasta', u'primavera', u'was', u'nice', u'', u'and', u'the', u'soup', u'special', u'we', u'had', u'was', u'delicious', u'']\n"
     ]
    }
   ],
   "source": [
    "# we need to flatten sentences list since we have a triple level list\n",
    "# that we need to convert to a list of lists (2 levels)\n",
    "sentence_list = [item for sublist in sentences for item in sublist]\n",
    "\n",
    "# format will be ok with word2vector\n",
    "print sentence_list[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444454"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have aroiund 444000 sentences minded from 50K reviews of\n",
    "# Toronto restaurants\n",
    "print len(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-21 19:34:27,588 : INFO : collecting all words and their counts\n",
      "2018-01-21 19:34:27,593 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-01-21 19:34:27,667 : INFO : PROGRESS: at sentence #10000, processed 166483 words, keeping 9036 word types\n",
      "2018-01-21 19:34:27,735 : INFO : PROGRESS: at sentence #20000, processed 332568 words, keeping 12587 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-21 19:34:27,800 : INFO : PROGRESS: at sentence #30000, processed 497948 words, keeping 15344 word types\n",
      "2018-01-21 19:34:27,845 : INFO : PROGRESS: at sentence #40000, processed 664084 words, keeping 17603 word types\n",
      "2018-01-21 19:34:27,912 : INFO : PROGRESS: at sentence #50000, processed 829665 words, keeping 19661 word types\n",
      "2018-01-21 19:34:27,958 : INFO : PROGRESS: at sentence #60000, processed 997906 words, keeping 21318 word types\n",
      "2018-01-21 19:34:28,028 : INFO : PROGRESS: at sentence #70000, processed 1168609 words, keeping 23082 word types\n",
      "2018-01-21 19:34:28,109 : INFO : PROGRESS: at sentence #80000, processed 1333955 words, keeping 24453 word types\n",
      "2018-01-21 19:34:28,157 : INFO : PROGRESS: at sentence #90000, processed 1497282 words, keeping 25699 word types\n",
      "2018-01-21 19:34:28,211 : INFO : PROGRESS: at sentence #100000, processed 1663384 words, keeping 26999 word types\n",
      "2018-01-21 19:34:28,265 : INFO : PROGRESS: at sentence #110000, processed 1827603 words, keeping 28240 word types\n",
      "2018-01-21 19:34:28,315 : INFO : PROGRESS: at sentence #120000, processed 1994715 words, keeping 29279 word types\n",
      "2018-01-21 19:34:28,362 : INFO : PROGRESS: at sentence #130000, processed 2158219 words, keeping 30349 word types\n",
      "2018-01-21 19:34:28,434 : INFO : PROGRESS: at sentence #140000, processed 2324503 words, keeping 31317 word types\n",
      "2018-01-21 19:34:28,481 : INFO : PROGRESS: at sentence #150000, processed 2490142 words, keeping 32179 word types\n",
      "2018-01-21 19:34:28,532 : INFO : PROGRESS: at sentence #160000, processed 2657425 words, keeping 33173 word types\n",
      "2018-01-21 19:34:28,579 : INFO : PROGRESS: at sentence #170000, processed 2822402 words, keeping 34127 word types\n",
      "2018-01-21 19:34:28,622 : INFO : PROGRESS: at sentence #180000, processed 2988994 words, keeping 35025 word types\n",
      "2018-01-21 19:34:28,666 : INFO : PROGRESS: at sentence #190000, processed 3155085 words, keeping 35720 word types\n",
      "2018-01-21 19:34:28,726 : INFO : PROGRESS: at sentence #200000, processed 3321156 words, keeping 36514 word types\n",
      "2018-01-21 19:34:28,768 : INFO : PROGRESS: at sentence #210000, processed 3486079 words, keeping 37290 word types\n",
      "2018-01-21 19:34:28,816 : INFO : PROGRESS: at sentence #220000, processed 3653440 words, keeping 38121 word types\n",
      "2018-01-21 19:34:28,868 : INFO : PROGRESS: at sentence #230000, processed 3818864 words, keeping 38853 word types\n",
      "2018-01-21 19:34:28,912 : INFO : PROGRESS: at sentence #240000, processed 3985978 words, keeping 39610 word types\n",
      "2018-01-21 19:34:28,957 : INFO : PROGRESS: at sentence #250000, processed 4151614 words, keeping 40416 word types\n",
      "2018-01-21 19:34:29,002 : INFO : PROGRESS: at sentence #260000, processed 4316235 words, keeping 41110 word types\n",
      "2018-01-21 19:34:29,047 : INFO : PROGRESS: at sentence #270000, processed 4479798 words, keeping 41789 word types\n",
      "2018-01-21 19:34:29,098 : INFO : PROGRESS: at sentence #280000, processed 4648025 words, keeping 42516 word types\n",
      "2018-01-21 19:34:29,160 : INFO : PROGRESS: at sentence #290000, processed 4814506 words, keeping 43131 word types\n",
      "2018-01-21 19:34:29,204 : INFO : PROGRESS: at sentence #300000, processed 4976106 words, keeping 43711 word types\n",
      "2018-01-21 19:34:29,256 : INFO : PROGRESS: at sentence #310000, processed 5143927 words, keeping 44395 word types\n",
      "2018-01-21 19:34:29,314 : INFO : PROGRESS: at sentence #320000, processed 5310846 words, keeping 44985 word types\n",
      "2018-01-21 19:34:29,358 : INFO : PROGRESS: at sentence #330000, processed 5474969 words, keeping 45598 word types\n",
      "2018-01-21 19:34:29,413 : INFO : PROGRESS: at sentence #340000, processed 5641955 words, keeping 46200 word types\n",
      "2018-01-21 19:34:29,495 : INFO : PROGRESS: at sentence #350000, processed 5808506 words, keeping 46846 word types\n",
      "2018-01-21 19:34:29,560 : INFO : PROGRESS: at sentence #360000, processed 5971934 words, keeping 47441 word types\n",
      "2018-01-21 19:34:29,613 : INFO : PROGRESS: at sentence #370000, processed 6136171 words, keeping 48012 word types\n",
      "2018-01-21 19:34:29,660 : INFO : PROGRESS: at sentence #380000, processed 6300519 words, keeping 48712 word types\n",
      "2018-01-21 19:34:29,720 : INFO : PROGRESS: at sentence #390000, processed 6468919 words, keeping 49297 word types\n",
      "2018-01-21 19:34:29,765 : INFO : PROGRESS: at sentence #400000, processed 6637032 words, keeping 49905 word types\n",
      "2018-01-21 19:34:29,845 : INFO : PROGRESS: at sentence #410000, processed 6807466 words, keeping 50445 word types\n",
      "2018-01-21 19:34:29,896 : INFO : PROGRESS: at sentence #420000, processed 6974810 words, keeping 50970 word types\n",
      "2018-01-21 19:34:29,946 : INFO : PROGRESS: at sentence #430000, processed 7141392 words, keeping 51572 word types\n",
      "2018-01-21 19:34:30,003 : INFO : PROGRESS: at sentence #440000, processed 7307073 words, keeping 52077 word types\n",
      "2018-01-21 19:34:30,026 : INFO : collected 52339 word types from a corpus of 7381114 raw words and 444454 sentences\n",
      "2018-01-21 19:34:30,029 : INFO : Loading a fresh vocabulary\n",
      "2018-01-21 19:34:30,136 : INFO : min_count=30 retains 6793 unique words (12% of original 52339, drops 45546)\n",
      "2018-01-21 19:34:30,139 : INFO : min_count=30 leaves 7199327 word corpus (97% of original 7381114, drops 181787)\n",
      "2018-01-21 19:34:30,179 : INFO : deleting the raw counts dictionary of 52339 items\n",
      "2018-01-21 19:34:30,191 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2018-01-21 19:34:30,193 : INFO : downsampling leaves estimated 4759464 word corpus (66.1% of prior 7199327)\n",
      "2018-01-21 19:34:30,194 : INFO : estimated required memory for 6793 words and 200 dimensions: 14265300 bytes\n",
      "2018-01-21 19:34:30,224 : INFO : resetting layer weights\n",
      "2018-01-21 19:34:30,333 : INFO : training model with 2 workers on 6793 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-01-21 19:34:31,346 : INFO : PROGRESS: at 1.38% examples, 326923 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:32,355 : INFO : PROGRESS: at 2.88% examples, 342446 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:33,399 : INFO : PROGRESS: at 4.05% examples, 316287 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:34,402 : INFO : PROGRESS: at 5.77% examples, 338028 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:35,412 : INFO : PROGRESS: at 8.39% examples, 393668 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:36,424 : INFO : PROGRESS: at 11.07% examples, 432981 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:37,424 : INFO : PROGRESS: at 13.44% examples, 450859 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:38,436 : INFO : PROGRESS: at 15.68% examples, 460711 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:39,442 : INFO : PROGRESS: at 18.17% examples, 474924 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:40,444 : INFO : PROGRESS: at 20.89% examples, 492233 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:41,455 : INFO : PROGRESS: at 23.56% examples, 504853 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:42,466 : INFO : PROGRESS: at 26.25% examples, 515358 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:43,474 : INFO : PROGRESS: at 28.98% examples, 525343 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:44,482 : INFO : PROGRESS: at 31.31% examples, 527227 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:45,479 : INFO : PROGRESS: at 33.98% examples, 533916 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:46,490 : INFO : PROGRESS: at 36.34% examples, 535217 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:47,506 : INFO : PROGRESS: at 38.57% examples, 534690 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:48,517 : INFO : PROGRESS: at 40.89% examples, 535453 words/s, in_qsize 3, out_qsize 0\n",
      "2018-01-21 19:34:49,519 : INFO : PROGRESS: at 43.15% examples, 535660 words/s, in_qsize 3, out_qsize 0\n",
      "2018-01-21 19:34:50,531 : INFO : PROGRESS: at 45.44% examples, 535634 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:51,539 : INFO : PROGRESS: at 47.25% examples, 530453 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:52,553 : INFO : PROGRESS: at 48.77% examples, 522504 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:53,556 : INFO : PROGRESS: at 51.40% examples, 526786 words/s, in_qsize 3, out_qsize 0\n",
      "2018-01-21 19:34:54,566 : INFO : PROGRESS: at 54.08% examples, 531151 words/s, in_qsize 4, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-21 19:34:55,566 : INFO : PROGRESS: at 56.48% examples, 532605 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:56,578 : INFO : PROGRESS: at 58.94% examples, 534634 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:57,580 : INFO : PROGRESS: at 61.57% examples, 537883 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:58,584 : INFO : PROGRESS: at 64.19% examples, 540920 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:34:59,587 : INFO : PROGRESS: at 66.90% examples, 544368 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:00,595 : INFO : PROGRESS: at 69.23% examples, 544559 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:01,605 : INFO : PROGRESS: at 71.86% examples, 546929 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:02,614 : INFO : PROGRESS: at 74.52% examples, 549361 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:03,617 : INFO : PROGRESS: at 77.16% examples, 551622 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:04,621 : INFO : PROGRESS: at 79.78% examples, 553914 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:05,623 : INFO : PROGRESS: at 82.41% examples, 555891 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:06,630 : INFO : PROGRESS: at 85.06% examples, 557887 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:07,630 : INFO : PROGRESS: at 87.63% examples, 559313 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:08,636 : INFO : PROGRESS: at 89.34% examples, 555221 words/s, in_qsize 3, out_qsize 0\n",
      "2018-01-21 19:35:09,648 : INFO : PROGRESS: at 90.96% examples, 550739 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:10,657 : INFO : PROGRESS: at 92.50% examples, 546027 words/s, in_qsize 3, out_qsize 0\n",
      "2018-01-21 19:35:11,669 : INFO : PROGRESS: at 94.60% examples, 544678 words/s, in_qsize 3, out_qsize 0\n",
      "2018-01-21 19:35:12,687 : INFO : PROGRESS: at 96.37% examples, 541489 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:13,702 : INFO : PROGRESS: at 98.92% examples, 542928 words/s, in_qsize 4, out_qsize 0\n",
      "2018-01-21 19:35:14,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-01-21 19:35:14,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-01-21 19:35:14,115 : INFO : training on 36905570 raw words (23799643 effective words) took 43.8s, 543698 effective words/s\n",
      "2018-01-21 19:35:14,116 : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-01-21 19:35:14,212 : INFO : saving Word2Vec object under 200features_30minwords_10context, separately None\n",
      "2018-01-21 19:35:14,214 : INFO : not storing attribute syn0norm\n",
      "2018-01-21 19:35:14,215 : INFO : not storing attribute cum_table\n",
      "2018-01-21 19:35:14,274 : INFO : saved 200features_30minwords_10context\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it to have clean messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 200    # Word vector dimensionality                      \n",
    "min_word_count = 30   # Minimum word count                        \n",
    "num_workers = 2       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# train word2vec model based on my 50K review sample\n",
    "from gensim.models import word2vec\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(sentence_list, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"200features_30minwords_10context\"\n",
    "model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'gross', 0.7470200061798096),\n",
       " (u'awful', 0.7391952276229858),\n",
       " (u'edible', 0.6546488404273987),\n",
       " (u'tasteless', 0.6506273746490479),\n",
       " (u'meh', 0.6375978589057922),\n",
       " (u'horrible', 0.6174851655960083),\n",
       " (u'bland', 0.6133884787559509),\n",
       " (u'alright', 0.6046308279037476),\n",
       " (u'terrible', 0.6013745069503784),\n",
       " (u'inedible', 0.596312403678894)]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# terms most similar to sushi\n",
    "#print model.wv.most_similar(\"sushi\")\n",
    "# terms most similar to sushi\n",
    "model.wv.most_similar(\"disgusting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should we need to load the model\n",
    "#model = word2vec.Word2Vec.load(\"200features_30minwords_10context\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6793, 200)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.wv.syn0 consists of a feature vector for each work\n",
    "type(model.wv.syn0)\n",
    "# with a min word count of 30, a vocab of 6,793 words as created\n",
    "len(model.wv.vocab)\n",
    "# shape of wv.syn0 should be 6793, 200\n",
    "model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'seafood', 0.5753906965255737),\n",
       " (u'noodles', 0.5618176460266113),\n",
       " (u'udon', 0.5462554693222046),\n",
       " (u'broccoli', 0.5354248285293579),\n",
       " (u'vegetable', 0.5339387059211731),\n",
       " (u'rice', 0.5258795022964478),\n",
       " (u'bibimbap', 0.5200287103652954),\n",
       " (u'noodle', 0.5142123103141785),\n",
       " (u'mein', 0.509763240814209),\n",
       " (u'soba', 0.5056496858596802)]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 200 dimension feature vector returned for word 'italian'\n",
    "model.wv[\"italian\"].shape\n",
    "model.wv.most_similar(positive=['pasta','chinese'], negative=['italian'])\n",
    "#model.wv.most_similar('disgusting')\n",
    "#model.wv.most_similar('fresh')\n",
    "#model.wv.most_similar(positive=['kobe','beef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feature vector composed of the average of word vectors in\n",
    "# a review's paragraph\n",
    "def convert_review_feature_vector(word_list, model, feature_count):\n",
    "    # initialise array of length feature_count (200 )\n",
    "    feature_vector = np.zeros((feature_count,), dtype='float32')\n",
    "    # stores count of words that are features in learned vocab\n",
    "    word_count = 0.\n",
    "    # convert learned vocab to set for faster processing\n",
    "    vocab_set = set(model.wv.index2word)\n",
    "    # iterate over words in word_list, adding feature vectors together\n",
    "    for word in word_list:\n",
    "        if word in vocab_set:\n",
    "            word_count += 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    \n",
    "    # finally divide feature_vector by number of words ot get arithmetic vector mean\n",
    "    feature_vector = np.divide(feature_vector, word_count)\n",
    "    return feature_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews2 = pd_review[\"text\"].apply(lambda x: process_review(x, remove_stop=True))\n",
    "# creates a 2D array of feature vector of size review count x feature count\n",
    "review_vectors =\\\n",
    "np.array(clean_reviews2.apply(lambda x: \n",
    "                              convert_review_feature_vector(x, model, 200)).tolist())\n",
    "\n",
    "# def process_review(base_review, remove_stop=False, stem = False, join=False):\n",
    "#convert_review_feature_vector(['excellent','thai','curry'], model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for search:  2.60874795914 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "search_string = \"vegan curry\"\n",
    "\n",
    "search_vect = convert_review_feature_vector(search_string.split(), model, 200)\n",
    "\n",
    "from scipy import spatial\n",
    "# calculate cosine similarity of search string with review vectors\n",
    "distances = []\n",
    "for rv in review_vectors:\n",
    "    distances.append(spatial.distance.cosine(search_vect, rv))\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for search: \", elapsed, \"seconds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Banjara Indian Cuisine', 0.3259483575820923),\n",
       " (u'Flip Toss & Thai Kitchen', 0.3838837742805481),\n",
       " (u'Picnic', 0.3978135585784912),\n",
       " (u'Golden Thai Restaurant', 0.4034334421157837),\n",
       " (u'Thai Restaurant', 0.43333888053894043),\n",
       " (u'Vital Life', 0.43357789516448975),\n",
       " (u'Saffron Spice Kitchen', 0.4379618763923645),\n",
       " (u'Khao San Road', 0.43985843658447266),\n",
       " (u'EAT BKK Thai Kitchen', 0.44309723377227783),\n",
       " (u'Gandhi Cuisine', 0.4435776472091675),\n",
       " (u'Lime Asian Kitchen', 0.4474688768386841),\n",
       " (u\"Lee's Thai Spring Roll\", 0.44914722442626953),\n",
       " (u'Tabule Restaurant', 0.4529154896736145),\n",
       " (u'Naturalis Cafe', 0.4554935693740845),\n",
       " (u'Saffron Spice Kitchen', 0.4582432508468628),\n",
       " (u\"Pam's Caribbean Kitchen\", 0.46021604537963867),\n",
       " (u'The Real Jerk', 0.46623891592025757),\n",
       " (u'Eastern Twist', 0.4733338952064514),\n",
       " (u'Pho Rua Vang Golden Turtle', 0.47746366262435913),\n",
       " (u'Thai Elephant', 0.4776585102081299)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top 20 cosine similarity\n",
    "[(pd_review[\"name\"][x], distances[x]) for x in np.argsort(distances)[:20]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to project onto 2D using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_closestwords(model, word, feature_count):\n",
    "    \n",
    "    arr = np.empty((0,feature_count), dtype='f')\n",
    "    word_labels = [word]\n",
    "\n",
    "    # get close words\n",
    "    close_words = model.wv.similar_by_word(word)\n",
    "    \n",
    "    # add the vector for each of the closest words to the array\n",
    "    arr = np.append(arr, np.array([model.wv[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "        \n",
    "    # find tsne coords for 2 dimensions\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    #np.set_printoptions(suppress=True)\n",
    "    result = tsne.fit_transform(arr)\n",
    "\n",
    "    x_coords = result[:, 0]\n",
    "    y_coords = result[:, 1]\n",
    "    # display scatter plot\n",
    "    #fig = plt.figure(figsize=(20, 10))\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEACAYAAADx33KKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n84gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f741e912a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
